# Copyright 2023 solo-learn development team.

# Permission is hereby granted, free of charge, to any person obtaining a copy of
# this software and associated documentation files (the "Software"), to deal in
# the Software without restriction, including without limitation the rights to use,
# copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the
# Software, and to permit persons to whom the Software is furnished to do so,
# subject to the following conditions:

# The above copyright notice and this permission notice shall be included in all copies
# or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
# INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR
# PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE
# FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
# OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
# DEALINGS IN THE SOFTWARE.


import io
import os
import csv
import random
import numpy as np
import logging
from pathlib import Path
from typing import Callable, Optional

import h5py
from PIL import Image
from torch.utils.data import Dataset
from tqdm import tqdm

from torchvision.transforms import *
from src.utils import *
from src.utils.misc import imread
from datasets import load_dataset

class H5Dataset(Dataset):
    def __init__(
        self,
        dataset: str,
        h5_path: str,
        transform: Optional[Callable] = None,
    ):
        """H5 Dataset.
        The dataset assumes that data is organized as:
            "class_name"
                "img_name"
                "img_name"
                "img_name"
            "class_name"
                "img_name"
                "img_name"
                "img_name"

        Args:
            dataset (str): dataset name.
            h5_path (str): path of the h5 file.
            transform (Callable): pipeline of transformations. Defaults to None.
        """

        self.h5_path = h5_path
        self.h5_file = None
        self.transform = transform

        assert dataset in ["imagenet100", "imagenet", "custom"], "Invalid dataset name."

        self._load_h5_data_info()

        # filter if needed to avoid having a copy of imagenet100 data
        if dataset == "imagenet100":
            script_folder = Path(os.path.dirname(__file__))
            classes_file = script_folder / "dataset_subset" / "imagenet100_classes.txt"
            with open(classes_file) as f:
                self.classes = f.readline().strip().split()
            self.classes = sorted(self.classes)
            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}

            class_set = set(self.classes)
            new_data = []
            for class_name, img_name, _ in self._data:
                if class_name in class_set:
                    new_data.append((class_name, img_name, self.class_to_idx[class_name]))
            if not new_data:
                logging.warn(
                    "Skipped filtering. Tried to filter classes for imagenet100, "
                    "but wasn't able to do so. Either make sure that you do not "
                    "rely on the filtering, i.e. your h5 file is already filtered "
                    "or make sure the class names are the default ones."
                )
            else:
                self._data = new_data

    def _load_h5_data_info(self):
        self._data = []
        h5_data_info_file = os.path.join(
            os.path.expanduser("~"), os.path.basename(os.path.splitext(self.h5_path)[0]) + ".txt"
        )
        if not os.path.isfile(h5_data_info_file):
            temp_h5_file = h5py.File(self.h5_path, "r")

            # collect data from the h5 file directly
            self.classes, self.class_to_idx = self._find_classes(temp_h5_file)
            for class_name in tqdm(self.classes, desc="Collecting information about the h5 file"):
                y = self.class_to_idx[class_name]
                for img_name in temp_h5_file[class_name].keys():
                    self._data.append((class_name, img_name, int(y)))

            # save the info locally to speed up sequential executions
            with open(h5_data_info_file, "w") as f:
                for class_name, img_name, y in self._data:
                    f.write(f"{class_name}/{img_name} {y}\n")
        else:
            # load data info file that was already generated by previous runs
            with open(h5_data_info_file) as f:
                for line in f:
                    class_name_img, y = line.strip().split(" ")
                    class_name, img_name = class_name_img.split("/")
                    self._data.append((class_name, img_name, int(y)))

    def _find_classes(self, h5_file: h5py.File):
        classes = sorted(h5_file.keys())
        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
        return classes, class_to_idx

    def _load_img(self, class_name: str, img: str):
        img = self.h5_file[class_name][img][:]
        img = Image.open(io.BytesIO(img)).convert("RGB")
        return img

    def __getitem__(self, index: int):
        if self.h5_file is None:
            self.h5_file = h5py.File(self.h5_path, "r")

        class_name, img, y = self._data[index]

        x = self._load_img(class_name, img)
        if self.transform:
            x = self.transform(x)

        return x, y

    def __len__(self):
        return len(self._data)

# ========================================================== UNLABELLED Dataset ========================================================== #

class IDRCell100K(Dataset):
    def __init__(self, root_dir=None, train=True, transform=None, shuffle=False, sample_ratio=1.0):
        self.root_dir = root_dir
        self.train = train
        self.transform = transform
        self.file_list = self._collect_files()
        self.sample_ratio = sample_ratio  # The ratio of images to sample

        if shuffle:
            random.shuffle(self.file_list)

    def __getitem__(self, index):
        image_id, channel_paths = self.file_list[index]
        if isinstance(channel_paths, str):
            file_paths = eval(channel_paths)
        else:
            file_paths = channel_paths

        image_channels = []
        for file_path in file_paths:
            image = Image.open(file_path)
            channel_array = np.array(image)[:, :, np.newaxis]  # Add a new axis to make it 3-dimensional
            image_channels.append(channel_array)

        image_array = np.concatenate(image_channels, axis=2).astype(np.float32)

        if self.transform is not None:
            augmented_image = self.transform(image=image_array)

        # ========= IF YOU WANT TO VIZUALIZE THE TRANSFORMATION YOU DO ========= #
        # if self.train:
        #    vizualize_aug(save_dir='.', raw_image=image_array, augmented_image=augmented_image, index_to_query=image_id)

        return augmented_image, -1 #returning a dummy label

    def __len__(self):
        return len(self.file_list)

    def _collect_files(self):
        file_list = []

        if self.train:
            self.csv_file = os.path.join(self.root_dir, 'train.csv')
        else:
            self.csv_file = os.path.join(self.root_dir, 'test.csv')

        with open(self.csv_file, 'r') as file:
            reader = csv.reader(file)
            for row in reader:
                image_id = row[0]
                channel_paths = row[1]
                try:
                    # check consistency of channel paths if encapsulated in a string, and convert to list
                    channel_paths = eval(channel_paths)
                except (NameError, SyntaxError):
                    pass
                # Add self.root_dir for each channel path
                channel_paths = [os.path.join(self.root_dir,'images',channel_path)for channel_path in channel_paths]
                file_list.append((image_id, channel_paths))

        return file_list

class IDRCell100K_3Channels(Dataset):
    '''
    Used only for a baseline comparison with a Standard ViT trained on 3 channels images.
    '''
    def __init__(self, root_dir=None, train=True, transform=None, shuffle=False, sample_ratio=1.0):
        self.root_dir = root_dir
        self.train = train
        self.transform = transform
        self.file_list = self._collect_files()
        self.sample_ratio = sample_ratio  # The ratio of images to sample

        if shuffle:
            random.shuffle(self.file_list)

    def __getitem__(self, index):
        image_id, channel_paths = self.file_list[index]
        if isinstance(channel_paths, str):
            file_paths = eval(channel_paths)
        else:
            file_paths = channel_paths

        image_channels = []
        for file_path in file_paths:
            image = Image.open(file_path)
            channel_array = np.array(image)[:, :, np.newaxis]  # Add a new axis to make it 3-dimensional
            image_channels.append(channel_array)

        image_array = np.concatenate(image_channels, axis=2).astype(np.float32)

        if self.transform is not None:
            augmented_image = self.transform(image=image_array)

        # ========= IF YOU WANT TO VIZUALIZE THE TRANSFORMATION YOU DO ========= #
        # if self.train:
        #    vizualize_aug(save_dir='.', raw_image=image_array, augmented_image=augmented_image, index_to_query=image_id)

        return augmented_image, -1 #returning a dummy label

    def __len__(self):
        return len(self.file_list)

    def _collect_files(self):
        file_list = []

        if self.train:
            self.csv_file = os.path.join(self.root_dir, 'train.csv')
        else:
            self.csv_file = os.path.join(self.root_dir, 'test.csv')

        with open(self.csv_file, 'r') as file:
            reader = csv.reader(file)
            for row in reader:
                image_id = row[0]
                channel_paths = row[1]
                try:
                    # check consistency of channel paths if encapsulated in a string, and convert to list
                    channel_paths = eval(channel_paths)
                except (NameError, SyntaxError):
                    pass
                # Add self.root_dir for each channel path
                channel_paths = [os.path.join(self.root_dir,'images',channel_path)for channel_path in channel_paths]
                
                # Filter out images with less than 3 channels
                if len(channel_paths) >= 3:
                    # Take the first 3 channels
                    channel_paths = channel_paths[:3]
                    file_list.append((image_id, channel_paths))

        return file_list
      
class Bray(Dataset):
    def __init__(self, root_dir=None, train=True, transform=None, shuffle=False, sample_ratio=1.0):
        self.root_dir = root_dir
        self.train = train
        self.transform = transform
        self.file_list = self._collect_files()
        self.sample_ratio = sample_ratio  # The ratio of images to sample

        if shuffle:
            random.shuffle(self.file_list)

    def __getitem__(self, index):
        img_path = self.file_list[index]

        image_array = np.load(img_path)
        image_array = image_array['sample'].astype(np.float32)

        if self.transform is not None:
            augmented_image = self.transform(image=image_array)

        # ========= IF YOU WANT TO VIZUALIZE THE TRANSFORMATION YOU DO ========= #
        # if self.train:
        #    vizualize_aug(save_dir='.', raw_image=image_array, augmented_image=augmented_image, index_to_query=image_id)

        return augmented_image, -1 #returning a dummy label

    def __len__(self):
        return len(self.file_list)

    def _collect_files(self):
        file_list = []

        if self.train:
            self.csv_file = os.path.join(self.root_dir, 'bray_paths/train_split.csv')
        else:
            self.csv_file = os.path.join(self.root_dir, 'bray_paths/val_split.csv')

        with open(self.csv_file, 'r') as file:
            reader = csv.reader(file)
            next(reader)  # Skip the header row
            for row in reader:
                img_path = row[0]
                try:
                    # check consistency of channel paths if encapsulated in a string, and convert to list
                    img_path = eval(img_path)
                except (NameError, SyntaxError):
                    pass
                # Add self.root_dir for each channel path
                
                file_list.append(img_path)

        return file_list

class BBBC021xBray(Dataset):
    def __init__(self, root_dir=None, train=True, transform=None, shuffle=False, sample_ratio=1.0):
        self.root_dir = root_dir
        self.train = train
        self.transform = transform
        self.dataset_to_idx = {}  # New dictionary for dataset encoding
        self.target_to_idx = {}   # New dictionary for target encoding
        self.idx_to_dataset_name = {}  # New dictionary for dataset decoding
        self.idx_to_target_name = {} # New dictionary for target decoding
        self.file_list = self._collect_files()

        # Initialize the encoding dictionaries
        self._init_label_encoders()
        
        if shuffle:
            random.shuffle(self.file_list)

    def _init_label_encoders(self):
        datasets = set()
        targets = set()
        for _, dataset, target in self.file_list:
            datasets.add(dataset)
            targets.add(target)

        self.dataset_to_idx = {dataset: idx for idx, dataset in enumerate(datasets)}
        self.target_to_idx = {target: idx for idx, target in enumerate(targets)}

        # Also create reverse mappings
        self.idx_to_dataset_name = {idx: name for name, idx in self.dataset_to_idx.items()}
        self.idx_to_target_name = {idx: name for name, idx in self.target_to_idx.items()}

    def __getitem__(self, index):
        channel_paths, dataset, target = self.file_list[index]

        # BBBC021 images
        if dataset == 'bbbc021':
            if isinstance(channel_paths, str):
                file_paths = eval(channel_paths)
            else:
                file_paths = channel_paths

            image_channels = []
            for file_path in file_paths:
                image = Image.open(file_path)
                channel_array = np.array(image)[:, :, np.newaxis]  # Add a new axis to make it 3-dimensional
                image_channels.append(channel_array)

            image_array = np.concatenate(image_channels, axis=2).astype(np.float32)

        # Bray images
        elif dataset == 'bray':
            img = np.load(channel_paths, allow_pickle=True)
            image_array = img['sample']
    
        # Put the image to float32 pixel intensities
        image_array = image_array.astype(np.float32)

        if self.transform is not None:
            augmented_image = self.transform(image=image_array)

        # ========= IF YOU WANT TO VIZUALIZE THE TRANSFORMATION YOU DO ========= #
        # if self.train:
        #    vizualize_aug(save_dir='.', raw_image=image_array, augmented_image=augmented_image, index_to_query=image_id)

        # Get the dataset and compound indices
        dataset_idx = self.dataset_to_idx[dataset]
        target_idx = self.target_to_idx[target]

        # Encode them into a single integer, using 10 bits for each
        combined_label = (dataset_idx << 10) | target_idx

        return augmented_image, combined_label

    def __len__(self):
        return len(self.file_list)

    def _collect_files(self):
        file_list = []

        # No train or val diff, just here for UMAP plot testing
        self.csv_file = os.path.join(self.root_dir, 'BBBC021xBray', 'train.csv')
        
        with open(self.csv_file, 'r') as file:
            reader = csv.reader(file)
            for row in reader:
                if row and row[0].startswith('['):
                    channel_paths_str = ','.join(row[:3])
                    channel_paths_str = channel_paths_str[1:-1]  # Remove the brackets
                    channel_paths_list = channel_paths_str.split("', '")
                    dataset = row[3]
                    target = row[4]
                    try:
                        channel_paths = [path.strip("'") for path in channel_paths_list]
                    except (ValueError, SyntaxError):
                        print(f"Error parsing channel paths: {channel_paths_list}")
                        continue
                    
                    # Check if the paths exist and join with the root directory
                    valid_channel_paths = []
                    non_valid_channel_paths = []
                    for channel_path in channel_paths:
                        full_path = os.path.join(self.root_dir, 'BBBC021', channel_path)
                        if os.path.exists(full_path):
                            valid_channel_paths.append(full_path)
                        else:
                            non_valid_channel_paths.append(full_path)
                    if valid_channel_paths:
                        file_list.append((valid_channel_paths, dataset, target))
                    if non_valid_channel_paths:
                        print(f"Channel paths do not exist: {non_valid_channel_paths}")

                else:
                    channel_paths = row[0]
                    dataset = row[1]
                    target = row[2]
                    
                    full_path = os.path.join(self.root_dir, 'Bray', channel_paths)
                    if os.path.exists(full_path):
                        file_list.append((full_path, dataset, target))
                    else:
                        print(f"Path does not exist: {full_path}")

        return file_list

# ========================================================== ClASSIFICATION Datasets ========================================================== #

########
# CELL #
########

class BloodMNIST(Dataset):
    """
    Description:
    ------------
    BloodMNIST is a dataset of 17,092 28x28 grayscale images.
    It is labelled as a multi-class problem, with 8 classes in total.
    License CC BY 4.0
    """
    img_channels = 3
    is_multiclass = True
    task = "classification"
    images_format = ".npz"
    int_to_labels = {
        0: "basophil",
        1: "eosinophil",
        2: "erythroblast",
        3: "immature granulocytes(myelocytes, metamyelocytes and promyelocytes)",
        4: "lymphocyte",
        5: "monocyte",
        6: "neutrophil",
        7: "platelet",
        }
    n_classes = len(int_to_labels)
    labels_to_int = {val: key for key, val in int_to_labels.items()}

    def __init__(self, root_dir=None, train=True, transform=None, shuffle=False, sample_ratio=1.0):
        self.root_dir = root_dir
        self.train = train
        self.transform = transform
        self.sample_ratio = sample_ratio  # The ratio of images to sample

        # Low Data Regime ONLY FOR TRAINING
        if self.train:
            if sample_ratio is not None and not 0 < sample_ratio <= 1:
                raise ValueError("Sample ratio must be between 0 and 1")

            file_list_name = f'train_BloodMNIST_{self.sample_ratio}.npz'
            self.file_list_path = os.path.join(self.root_dir, file_list_name)
            print(self.file_list_path)

            if os.path.exists(self.file_list_path) and os.path.isfile(self.file_list_path):
                # If the file list exists, load it
                print(f"Train file for ratio {sample_ratio} already exists, loading file list")
                self.file_list = self._load_file_list()
            else:
                # If the file list does not exist, generate it
                print(f"Train file for ratio {sample_ratio} does not exist, generating file list")
                self.file_list = self._collect_files()
                if sample_ratio:
                    self.file_list = random.sample(self.file_list, int(len(self.file_list) * sample_ratio))
                self._save_file_list()
        
        else:
            self.file_list = self._collect_files()

        if shuffle:
            random.shuffle(self.file_list)

    def __getitem__(self, index):
        tup = self.file_list[index]

        image_id = tup[0]
        label = tup[1]
    
        image = Image.fromarray(image_id)

        if self.transform is not None:
            image = self.transform(image)

        return image, label

    def __len__(self):
        return len(self.file_list)

    def _load_file_list(self):
        with np.load(self.file_list_path) as data:
            file_list = [(data['images'][i], data['labels'][i]) for i in range(data['images'].shape[0])]
        return file_list

    def _save_file_list(self):
        images, labels = zip(*self.file_list)  # Unpack the file list into images and labels
        np.savez_compressed(self.file_list_path, images=np.array(images), labels=np.array(labels))

    def _collect_files(self):
        data = np.load(os.path.join(self.root_dir, "bloodmnist.npz"))

        if self.train:
            images = data["train_images"]
            labels = np.squeeze(data["train_labels"])
        else:
            images = data["test_images"]
            labels = np.squeeze(data["test_labels"])

        data_list = [(img_numpy, label) for img_numpy, label in zip(images, labels)]

        return data_list

class BBBC021(Dataset):

    def __init__(self, root_dir: str, train:bool = True, transform: Optional[Callable] = None):
        self.train = train
        self.transform = transform
        self.root_dir = Path(root_dir)

        self.load_data()

    def __len__(self):
        return len(self.img_indices)

    def __getitem__(self, index):
        # Retrieve the index of the image to query according to the data_indices file (train or val)
        index_to_query = int(self.img_indices[index])

        # Query the image
        imgs_paths = self.img_paths[index_to_query]

        image_channels = []
        for img_path in imgs_paths:
            channel_array = np.array(imread(img_path))[:, :, np.newaxis]  # Add a new axis to make it 3-dimensional
            image_channels.append(channel_array)

        image = np.concatenate(image_channels, axis=2).astype(np.float32)
        label = self.labels[index_to_query][0]

        # Apply the transformations
        if self.transform is not None:
            image = self.transform(image)

        # ========= IF YOU WANT TO VIZUALIZE THE TRANSFORMATION YOU DO ========= #
        # vizualize_aug(self.root_dir, image, index_to_query)

        return image, label

    def load_data(self):
        """
        Description
        -----------
        Load the data from the dataset.

        Returns
        -------
        full_img_paths (list): list of the full paths of the images.
        img_indices (np.ndarray): vector of the absolute image indices of selected subset of BBBC021
        """
        data = np.load(self.root_dir, allow_pickle=True)
        img_paths = data['img_paths']
        labels = data['labels']
        dataset_dir = os.path.dirname(self.root_dir)

        # Group img_paths 3 by 3
        full_img_paths = [os.path.join(dataset_dir, img_path) for img_path in img_paths]
        grouped_img_paths = [full_img_paths[i:i+3] for i in range(0, len(full_img_paths), 3)]

        # Group labels 3 by 3
        labels = list(labels)
        grouped_labels = [labels[i:i+3] for i in range(0, len(labels), 3)]

        # Group concentrations 3 by 3
        concentrations = data['concentrations']
        grouped_concentrations = [concentrations[i:i+3] for i in range(0, len(concentrations), 3)]

        # Group compounds 3 by 3
        compounds = data['compounds']
        grouped_compounds = [compounds[i:i+3] for i in range(0, len(compounds), 3)]

        # Modify data
        self.img_paths = grouped_img_paths
        self.labels = grouped_labels
        self.concentrations = grouped_concentrations
        self.compounds = grouped_compounds

        self.img_indices = np.array(range(0, len(grouped_img_paths)))

    def get_labels(self, indices):
        labels = []
        for index in indices:
            labels.append(self.labels[index][0])
        return labels

    def get_compounds(self, indices):
        compounds = []
        for index in indices:
            compounds.append(self.compounds[index][0])
        return compounds

    def get_concentrations(self, indices):
        concentrations = []
        for index in indices:
            concentrations.append(self.concentrations[index][0])
        return concentrations

    def get_batches(self, indices, level='plate'):
        # Retrieve batch of each image
        batches = []
        for grouped_img_path in self.img_paths:
            batches.append(grouped_img_path[0].split('BBBC021/')[1].split('/')[0])
        if level=='week':
            batches = [batch.split('_')[0] for batch in batches]
        batches = np.array(batches)
        subset_batches = []
        for index in indices:
            subset_batches.append(batches[index])
        subset_batches = np.array(subset_batches)
        return subset_batches

class BBBC048(Dataset):
    """
    Description:
    ------------
    BBBC048 is the Cell Cycle Jurkat Cells dataset from the Broad Bioimage Benchmark Collection.
    This dataset contains 32,266 single cell images of asynchronously growing Jurkat cells that were captured with the ImageStream platform.
    The cells were fixed and stained with PI (propidium iodide) to quantify DNA content and a MPM2 (mitotic protein monoclonal #2) antibody to identify mitotic cells.
    """
    img_channels = 3
    is_multiclass = True
    task = "classification"
    images_format = ".jpg"
    int_to_labels = {
        0: "Anaphase",
        1: "Metaphase",
        2: "Prophase",
        3: "Telophase",
        4: "G1",
        5: "G2",
        6: "S",
        }
    n_classes = len(int_to_labels)
    labels_to_int = {val: key for key, val in int_to_labels.items()}

    def __init__(self, root_dir=None, train=True, transform=None, shuffle=False, sample_ratio=1.0):
        self.root_dir = root_dir
        self.train = train
        self.transform = transform
        self.file_list = self._collect_files()
        self.sample_ratio = sample_ratio  # The ratio of images to sample

        # Low Data Regime ONLY FOR TRAINING
        if self.train:
            if sample_ratio is not None and not 0 < sample_ratio <= 1:
                raise ValueError("Sample ratio must be between 0 and 1")

            file_list_name = f'train_BBBC048_{self.sample_ratio}.txt'
            self.file_list_path = os.path.join(self.root_dir, file_list_name)
            print(self.file_list_path)

            if os.path.exists(self.file_list_path) and os.path.isfile(self.file_list_path):
                # If the file list exists, load it
                print(f"Train file for ratio {sample_ratio} already exists, loading file list")
                self.file_list = self._load_file_list()
            else:
                # If the file list does not exist, generate it
                print(f"Train file for ratio {sample_ratio} does not exist, generating file list")
                self.file_list = self._collect_files()
                if sample_ratio:
                    self.file_list = random.sample(self.file_list, int(len(self.file_list) * sample_ratio))
                self._save_file_list()
        
        else:
            self.file_list = self._collect_files()

        if shuffle:
            random.shuffle(self.file_list)

    def __getitem__(self, index):

        tup = self.file_list[index]

        # parse the tuple
        image_id = tup[0]
        target = tup[1]
        channel_paths = tup[2]

        if isinstance(channel_paths, str):
            file_paths = eval(channel_paths)
        else:
            file_paths = channel_paths

        image_channels = []
        for file_path in file_paths:
            image = Image.open(file_path)
            channel_array = np.array(image)[:, :, np.newaxis]  # Add a new axis to make it 3-dimensional
            image_channels.append(channel_array)

        image_array = np.concatenate(image_channels, axis=2)

        if self.transform is not None:
            img = Image.fromarray(image_array)
            img = self.transform(img)

        return img, int(target)

    def __len__(self):
        return len(self.file_list)

    def _load_file_list(self):
        with open(self.file_list_path, 'r') as file:
            # This will create a list of lists, where each sub-list contains the elements
            # of a line as separate strings.
            file_list = []
            for line in file:
                # Split by comma, but we want to keep the curly braces part as one element
                parts = line.strip().split(',')
                # The first two elements are kept as they are, the rest is joined back
                elements = parts[:2]
                elements.append(','.join(parts[2:]))
                file_list.append(elements)
        return file_list

    def _save_file_list(self):
        with open(self.file_list_path, 'w') as file:
            for image_id, target, channel_paths in self.file_list:
                file.write(f"{image_id},{target},{channel_paths}\n")

    def _collect_files(self):
        file_list = []

        if self.train:
            self.csv_file = os.path.join(self.root_dir, 'train.csv')
        else:
            self.csv_file = os.path.join(self.root_dir, 'test.csv')

        with open(self.csv_file, 'r') as file:
            reader = csv.reader(file)
            for row in reader:
                image_id = row[0]
                target = row[1]
                channel_paths = row[2]
                try:
                    # check consistency of channel paths if encapsulated in a string, and convert to list
                    channel_paths = eval(channel_paths)
                except (NameError, SyntaxError):
                    pass
                channel_paths = [os.path.join(self.root_dir,channel_path)for channel_path in channel_paths]
                file_list.append((image_id, target, channel_paths))

        return file_list

class CyclOPS(Dataset):
    img_channels = 2
    is_multiclass = True
    task = "classification"
    images_format = ".tiff"
    int_to_labels = {
        0: "ACTIN",
        1: "BUDNECK",
        2: "BUDTIP",
        3: "CELLPERIPHERY",
        4: "CYTOPLASM",
        5: "ENDOSOME",
        6: "ER",
        7: "GOLGI",
        8: "MITOCHONDRIA", 
        9: "NUCLEARPERIPHERY",
        10: "NUCLEI",
        11: "NUCLEOLUS",
        12: "PEROXISOME",
        13: "SPINDLE",
        14: "SPINDLEPOLE",
        15: "VACUOLARMEMBRANE",
        16: "VACUOLE",
        }
    n_classes = len(int_to_labels)
    labels_to_int = {val: key for key, val in int_to_labels.items()}

    def __init__(self, root_dir=None, train=True, transform=None, shuffle=False, sample_ratio=1.0):
        self.root_dir = root_dir
        self.train = train
        self.transform = transform
        self.sample_ratio = sample_ratio  # The ratio of images to sample

        # Low Data Regime ONLY FOR TRAINING
        if self.train:
            if sample_ratio is not None and not 0 < sample_ratio <= 1:
                raise ValueError("Sample ratio must be between 0 and 1")

            file_list_name = f'train_CyclOPS_{self.sample_ratio}.txt'
            self.file_list_path = os.path.join(self.root_dir, file_list_name)
            print(self.file_list_path)

            if os.path.exists(self.file_list_path) and os.path.isfile(self.file_list_path):
                # If the file list exists, load it
                print(f"Train file for ratio {sample_ratio} already exists, loading file list")
                self.file_list = self._load_file_list()
            else:
                # If the file list does not exist, generate it
                print(f"Train file for ratio {sample_ratio} does not exist, generating file list")
                self.file_list = self._collect_files()
                if sample_ratio:
                    self.file_list = random.sample(self.file_list, int(len(self.file_list) * sample_ratio))
                self._save_file_list()
        
        else:
            self.file_list = self._collect_files()

        if shuffle:
            random.shuffle(self.file_list)

    def __getitem__(self, index):
        tup = self.file_list[index]

        # parse the tuple
        class_folder = tup[0]
        image_id = tup[1]
        channel_names = tup[2]

        # Collect the file path for the given image_id
        file_path = os.path.join(self.root_dir, class_folder, f"{class_folder}_{image_id}.tif")

        # Read the multi-channel image using PIL (Pillow)
        image_channels = []

        # Destringify the channel_names
        try:
            channel_names = eval(channel_names)
        except (NameError, SyntaxError):
            raise ValueError(f"Channel names {channel_names} must be a list of strings")

        for channel_name in channel_names:
            channel_file_path = file_path.replace(".tif", f"_{channel_name}.tif")
            image = Image.open(channel_file_path)
            image = np.clip(image, 0, 255).astype(np.uint8)
            channel_array = np.array(image)[:, :, np.newaxis]  # Add a new axis to make it 3-dimensional
            image_channels.append(channel_array)

        image_array = np.concatenate(image_channels, axis=2)

        # Get the integer label from the class name using labels_to_int dictionary
        label = self.labels_to_int[class_folder]

        if self.transform is not None:
            img = Image.fromarray(image_array)
            augmented_image = self.transform(img)

        # ========= IF YOU WANT TO VIZUALIZE THE TRANSFORMATION YOU DO ========= #
        # if self.train:
        #    vizualize_aug(save_dir=self.root_dir, raw_image=image_array, augmented_image=augmented_image,index_to_query=image_id)

        return augmented_image, int(label)

    def __len__(self):
        return len(self.file_list)

    def _load_file_list(self):
        with open(self.file_list_path, 'r') as file:
            # This will create a list of lists, where each sub-list contains the elements
            # of a line as separate strings.
            file_list = []
            for line in file:
                # Split by comma, but we want to keep the curly braces part as one element
                parts = line.strip().split(',')
                # The first two elements are kept as they are, the rest is joined back
                elements = parts[:2]
                elements.append(','.join(parts[2:]))
                file_list.append(elements)
        return file_list

    def _save_file_list(self):
        with open(self.file_list_path, 'w') as file:
            for class_folder, image_id, channel_names in self.file_list:
                file.write(f"{class_folder},{image_id},{channel_names}\n")

    def _collect_files(self):
        file_list = []

        if self.train:
            self.csv_file = os.path.join(self.root_dir, 'train.csv')
        else:
            self.csv_file = os.path.join(self.root_dir, 'val.csv')

        with open(self.csv_file, 'r') as file:
            reader = csv.reader(file)
            for row in reader:
                class_folder = row[0]
                image_id = row[1]
                channel_names = row[2]
                file_list.append((class_folder, image_id, channel_names))

        return file_list


##########
# TISSUE #
##########

class TissueMNIST(Dataset):
    """
    Description:
    ------------
    TissueMNIST is a dataset of 236,386 28x28 grayscale images.
    It uses the BBBC051, available from the Broad Bioimage Benchmark Collection. The dataset contains 236,386 human kidney cortex cells, segmented from 3 reference tissue specimens and organized into 8 categories.
    It splits the source dataset with a ratio of 7:1:2 into training, validation and test set. Each gray-scale image is 32x32x7 pixels, where 7 denotes 7 slices.
    We take maximum values across the slices and resize them into 28x28 gray-scale images.
    License: CC BY 4.0
    """

    img_channels = 1
    is_multiclass = True
    task = "classification"
    mean = (0.415, 0.221, 0.073) # TO BE CHANGED
    std = (0.275, 0.150, 0.081) # TO BE CHANGED
    images_format = ".npz"
    int_to_labels = {
        0: "Collecting Duct, Connecting Tubule",
        1: "Distal Convoluted Tubule",
        2: "Glomerular endothelial cells",
        3: "Interstitial endothelial cells",
        4: "Leukocytes",
        5: "Podocytes",
        6: "Proximal Tubule Segments",
        7: "Thick Ascending Limb",
    }
    target_metric = "roc_auc"
    knn_nhood = 200
    n_classes = len(int_to_labels)
    labels_to_int = {val: key for key, val in int_to_labels.items()}

    def __init__(self, root_dir=None, train=True, transform=None, shuffle=False, sample_ratio=1.0):
        self.root_dir = root_dir
        self.train = train
        self.transform = transform
        self.sample_ratio = sample_ratio  # The ratio of images to sample

        # Low Data Regime ONLY FOR TRAINING
        if self.train:
            if sample_ratio is not None and not 0 < sample_ratio <= 1:
                raise ValueError("Sample ratio must be between 0 and 1")

            file_list_name = f'train_TissueMNIST_{self.sample_ratio}.txt'
            self.file_list_path = os.path.join(self.root_dir, file_list_name)
            print(self.file_list_path)

            if os.path.exists(self.file_list_path) and os.path.isfile(self.file_list_path):
                # If the file list exists, load it
                print(f"Train file for ratio {sample_ratio} already exists, loading file list")
                self.file_list = self._load_file_list()
            else:
                # If the file list does not exist, generate it
                print(f"Train file for ratio {sample_ratio} does not exist, generating file list")
                self.file_list = self._collect_files()
                if sample_ratio:
                    self.file_list = random.sample(self.file_list, int(len(self.file_list) * sample_ratio))
                self._save_file_list()

        else:
            self.file_list = self._collect_files()

        if shuffle:
            random.shuffle(self.file_list)

    def __getitem__(self, index):
        tup = self.file_list[index]

        image_id = tup[0]
        label = tup[1] 

        image = Image.open(image_id)
        image_numpy = np.array(image)

        if self.transform is not None:
            image_array = self.transform(image_numpy)

        return image_array, label

    def __len__(self):
        return len(self.file_list)

    def _load_file_list(self):
        with open(self.file_list_path, 'r') as file:
            file_list = [tuple(line.strip().split(',')) for line in file.readlines()]
        return file_list

    def _save_file_list(self):
        with open(self.file_list_path, 'w') as file:
            for img_numpy, label in self.file_list:
                file.write(f"{img_numpy},{label}\n")

    def _collect_files(self):
        data = np.load(os.path.join(self.root_dir, "tissuemnist.npz"))

        if self.train:
            images = data["train_images"]
            labels = np.squeeze(data["train_labels"])
        else:
            images = data["test_images"]
            labels = np.squeeze(data["test_labels"])

        data_list = [(img_numpy, label) for img_numpy, label in zip(images, labels)]

        return data_list

# ========================================================== REGRESSION Datasets ========================================================== #

class Transloc(Dataset):
    """
    Description:
    ------------
    #TODO
    """
    img_channels = 3
    is_multiclass = True
    task = "regression"
    images_format = ".png"

    def __init__(self, root_dir=None, train=True, transform=None, shuffle=False, sample_ratio=1.0):
        self.root_dir = root_dir
        self.train = train
        self.transform = transform
        self.sample_ratio = sample_ratio  # The ratio of images to sample

        if self.train:
            if sample_ratio is not None and not 0 < sample_ratio <= 1:
                raise ValueError("Sample ratio must be between 0 and 1")

            file_list_name = f'train_Transloc_{self.sample_ratio}.txt'
            self.file_list_path = os.path.join(self.root_dir, file_list_name)
            print(self.file_list_path)

            if os.path.exists(self.file_list_path) and os.path.isfile(self.file_list_path):
                # If the file list exists, load it
                print(f"Train file for ratio {sample_ratio} already exists, loading file list")
                self.file_list = self._load_file_list()
            else:
                # If the file list does not exist, generate it
                print(f"Train file for ratio {sample_ratio} does not exist, generating file list")
                self.file_list = self._collect_files()
                if sample_ratio:
                    self.file_list = random.sample(self.file_list, int(len(self.file_list) * sample_ratio))
                self._save_file_list()
        
        else:
            self.file_list = self._collect_files()

        if shuffle:
            random.shuffle(self.file_list)

    def __getitem__(self, index):
        tup  = self.file_list[index]

        # parse the tuple
        image_path = tup[0]
        target = float(tup[1])

        image_array = np.array(Image.open(image_path))

        if self.transform is not None:
            img = Image.fromarray(image_array)
            img = self.transform(img)

        return img, target

    def __len__(self):
        return len(self.file_list)

    def _load_file_list(self):
        with open(self.file_list_path, 'r') as file:
            file_list = [tuple(line.strip().split(',')) for line in file.readlines()]
        return file_list

    def _save_file_list(self):
        with open(self.file_list_path, 'w') as file:
            for image_path, target in self.file_list:
                file.write(f"{image_path},{target}\n")

    def _collect_files(self):
        file_list = []

        if self.train:
            self.csv_file = os.path.join(self.root_dir, 'analyse_256x256', 'single_ratio_images_train.csv')
        else:
            self.csv_file = os.path.join(self.root_dir, 'analyse_256x256', 'single_ratio_images_val.csv')

        with open(self.csv_file, 'r') as file:
            reader = csv.DictReader(file, delimiter=',')
            for row in reader:
                category = row['cat']
                image_id = row['image_name']
                target = float(row['ratio'])

                # Add self.root_dir for each channel path
                image_path = os.path.join(self.root_dir, '256x256', category, image_id)
                file_list.append((image_path, target))

        return file_list

class MTBenchReg(Dataset):
    """
    Description:
    ------------
    #TODO
    """
    img_channels = 3
    is_multiclass = True
    task = "regression"
    images_format = ".tiff"

    def __init__(self, root_dir=None, train=True, transform=None, shuffle=False):
        self.root_dir = root_dir
        self.train = train
        self.transform = transform
    
        # No need for sample_ratio here since dataset is already in low data regime mode
        self.file_list = self._collect_files()

        if shuffle:
            random.shuffle(self.file_list)

    def __getitem__(self, index):
        tup = self.file_list[index]

        # Parse the tuple
        channels_paths = tup[0]
        target = float(tup[1])

        # Ensure channels_paths is a list of strings
        if not isinstance(channels_paths, list) or not all(isinstance(path, str) for path in channels_paths):
            raise ValueError(f"Channel paths must be a list of strings. Received: {channels_paths}")

        image_channels = []

        for channel_path in channels_paths:
            # Open image and convert to a consistent format (e.g., grayscale)
            image = Image.open(channel_path).convert('L')
            image_array = np.array(image)

            # Normalize between 0 and 255
            min_val = np.min(image_array)
            max_val = np.max(image_array)
            if max_val - min_val != 0:  # To avoid division by zero
                normalized_image = ((image_array - min_val) / (max_val - min_val)) * 255
            else:
                normalized_image = image_array

            normalized_image = normalized_image.astype(np.uint8)  # Ensure data type is uint8
            normalized_image = normalized_image[:, :, np.newaxis]  # Add a new axis
            image_channels.append(normalized_image)

        image_array = np.concatenate(image_channels, axis=2)

        if self.transform is not None:
            img = Image.fromarray(image_array)
            augmented_image = self.transform(img)
        else:
            augmented_image = image_array

        return augmented_image, target

    def __len__(self):
        return len(self.file_list)

    def _collect_files(self):
        file_list = []

        if self.train:
            self.csv_file = os.path.join(self.root_dir,'regress','MTB-MD-Regression_train.csv')
        else:
            self.csv_file = os.path.join(self.root_dir,'regress','MTB-MD-Regression_val.csv')

        with open(self.csv_file, 'r') as file:
            reader = csv.DictReader(file, delimiter=',')
            for row in reader:
                # instanciate list of channels paths
                channels_paths = []

                # take last two elements of the path
                channel_dapi = row['Dapi'].split('/')[-2:]
                channel_egfp = row['EGFP'].split('/')[-2:]
                channel_cy3 = row['Cy3'].split('/')[-2:]
                target = float(row['r² (2)'])

                # add each channel path in list

                # check if paths exist
                if os.path.exists(os.path.join(self.root_dir,'regress', *channel_dapi)) and os.path.exists(os.path.join(self.root_dir,'regress', *channel_egfp)) and os.path.exists(os.path.join(self.root_dir,'regress', *channel_cy3)):
                    channels_paths.append(os.path.join(self.root_dir,'regress', *channel_dapi))
                    channels_paths.append(os.path.join(self.root_dir,'regress', *channel_egfp))
                    channels_paths.append(os.path.join(self.root_dir,'regress', *channel_cy3))

                    # add tuple to file_list
                    file_list.append((channels_paths, target))

                else:
                    print(f"Path does not exist for {row['Dapi']} or {row['EGFP']} or {row['Cy3']}")

        return file_list
    

# ========================================================== DETECTION Datasets ========================================================== #

########
# CELL #
########

class BloodCellDetection(Dataset):
    """

    """
    img_channels = 1
    is_multiclass = True
    task = "classification"
    mean = (0.415, 0.221, 0.073) # TO BE CHANGED
    std = (0.275, 0.150, 0.081) # TO BE CHANGED
    images_format = ".npz"
    int_to_labels = {
        0: "Collecting Duct, Connecting Tubule",
        1: "Distal Convoluted Tubule",
        2: "Glomerular endothelial cells",
        3: "Interstitial endothelial cells",
        4: "Leukocytes",
        5: "Podocytes",
        6: "Proximal Tubule Segments",
        7: "Thick Ascending Limb",
    }
    target_metric = "roc_auc"
    knn_nhood = 200
    n_classes = len(int_to_labels)
    labels_to_int = {val: key for key, val in int_to_labels.items()}

    def __init__(self, root_dir=None, train=True, transform=None, shuffle=False):
        self.root_dir = root_dir
        self.train = train
        self.transform = transform
        self.file_list = self.get_data_as_list()

        if shuffle:
            random.shuffle(self.file_list)

    def __getitem__(self, index):
        image_id, label = self.file_list[index]

        image = Image.open(image_id)
        image_numpy = np.array(image)

        if self.transform is not None:
            img = Image.fromarray(image_numpy)
            img = self.transform(img)

        return img, label

    def __len__(self):
        return len(self.file_list)

    def get_data_as_list(self):
        data = load_dataset("keremberke/blood-cell-object-detection", name="full")

        if self.train:
            images = data["train_images"]
            labels = np.squeeze(data["train_labels"])
        else:
            images = data["test_images"]
            labels = np.squeeze(data["test_labels"])

        data_list = [(img_numpy, label) for img_numpy, label in zip(images, labels)]

        return data_list

class ZeroCostDL4Mic(Dataset):
    pass

# ========================================================== SEGMENTATION Datasets ========================================================== #

########
# CELL #
########

class LIVECell(Dataset):
    pass

class Cellpose(Dataset):
    pass

class BBBC038(Dataset):
    pass

class CellImageLibrary(Dataset):
    pass
